{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db6099a5-4ac9-450c-9503-41a3d44bca52",
   "metadata": {},
   "source": [
    "## Week 5 Homework \n",
    "\n",
    "In this homework we'll put what we learned about Spark in practice.\n",
    "\n",
    "For this homework we will be using the FHV 2019-10 data found here. [FHV Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2853dbe-cd88-496f-a50c-bd8fce97e808",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "\n",
    "**Install Spark and PySpark** \n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?\n",
    "\n",
    "> [!NOTE]\n",
    "> To install PySpark follow this [guide](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/05-batch/setup/pyspark.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50c9c3-beef-4285-970a-e6b31a7e9c40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59e6498-49a5-4c7b-828a-efe9639f950e",
   "metadata": {},
   "source": [
    "# Q1 - Answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77034c4-fe00-47d2-9647-037d5557320a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pyspark.__version__\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd2b41-2ca4-45c9-8fda-0e10942b0c0d",
   "metadata": {},
   "source": [
    "### Question 2: \n",
    "\n",
    "**FHV October 2019**\n",
    "\n",
    "Read the October 2019 FHV into a Spark Dataframe with a schema as we did in the lessons.\n",
    "\n",
    "Repartition the Dataframe to 6 partitions and save it to parquet.\n",
    "\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.\n",
    "\n",
    "- 1MB\n",
    "- 6MB\n",
    "- 25MB\n",
    "- 87MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38dc329c-b3b4-48f1-a885-4f6676abd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "month = 10\n",
    "type = 'fhv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b04f0bb-67f0-4a55-9131-027b88b9f69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz to data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv.gz\n",
      "--2024-03-05 17:27:22--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240305T162722Z&X-Amz-Expires=300&X-Amz-Signature=e832ce0929c351ef5c201ddc7e220eef8f13446b63e946efa5268b9b48933638&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-05 17:27:22--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240305T162722Z&X-Amz-Expires=300&X-Amz-Signature=e832ce0929c351ef5c201ddc7e220eef8f13446b63e946efa5268b9b48933638&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv.gz’\n",
      "\n",
      "data/raw/fhv/2019/1 100%[===================>]  18,48M  42,1MB/s    in 0,4s    \n",
      "\n",
      "2024-03-05 17:27:23 (42,1 MB/s) - ‘data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sh download_data.sh {type} {year} {month}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027d2f9-90a8-44e4-8bda-1a03ae834a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_fhv_pd = pd.read_csv(f'data/raw/{type}/{year}/{month:02d}/{type}_tripdata_{year}_{month:02d}.csv.gz', nrows=100)\n",
    "\n",
    "schema_ls = spark.createDataFrame(df_fhv_pd).schema\n",
    "f = open('_fhv_schema_def_', 'w')\n",
    "f.write(str(schema_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88abd0b1-b039-421c-a315-8a49c95ebbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: double (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "fhv_schema = types.StructType([\n",
    "     types.StructField('dispatching_base_num', types.StringType(), True)\n",
    "    ,types.StructField('pickup_datetime', types.TimestampType(), True)\n",
    "    ,types.StructField('dropoff_datetime', types.TimestampType(), True)\n",
    "    ,types.StructField('PULocationID', types.IntegerType(), True)\n",
    "    ,types.StructField('DOLocationID', types.IntegerType(), True)\n",
    "    ,types.StructField('SR_Flag', types.DoubleType(), True)\n",
    "    ,types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])\n",
    "\n",
    "in_fhv_path = f'data/raw/{type}/{year}/{month:02d}/'\n",
    "\n",
    "\n",
    "df_fhv = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(fhv_schema) \\\n",
    "    .csv(in_fhv_path)\n",
    "\n",
    "df_fhv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b10ec70e-c967-4f63-bec0-5d89d9b72bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "out_fhv_path = f'data/parquet/{type}/{year}/{month:02d}/'\n",
    "\n",
    "df_fhv \\\n",
    "    .repartition(6) \\\n",
    "    .write \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet(out_fhv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62daf39-065f-42fd-b403-98f99a668074",
   "metadata": {},
   "source": [
    "# Q2 - Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17db72a6-a4f9-4716-9b57-e5ed0a9d8e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 peter  staff   6.4M Mar  5 17:27 part-00000-f4616939-261a-4ae4-875e-8ca011547c8f-c000.snappy.parquet\n",
      "-rw-r--r--  1 peter  staff   6.3M Mar  5 17:27 part-00001-f4616939-261a-4ae4-875e-8ca011547c8f-c000.snappy.parquet\n",
      "-rw-r--r--  1 peter  staff   6.4M Mar  5 17:27 part-00002-f4616939-261a-4ae4-875e-8ca011547c8f-c000.snappy.parquet\n",
      "-rw-r--r--  1 peter  staff   6.4M Mar  5 17:27 part-00003-f4616939-261a-4ae4-875e-8ca011547c8f-c000.snappy.parquet\n",
      "-rw-r--r--  1 peter  staff   6.4M Mar  5 17:27 part-00004-f4616939-261a-4ae4-875e-8ca011547c8f-c000.snappy.parquet\n",
      "-rw-r--r--  1 peter  staff   6.4M Mar  5 17:27 part-00005-f4616939-261a-4ae4-875e-8ca011547c8f-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {out_fhv_path} | grep '.parquet' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b3247-7097-4a00-96dc-997b9e274ab7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#\n",
    "### Question 3: \n",
    "\n",
    "**Count records** \n",
    "\n",
    "How many taxi trips were there on the 15th of October?\n",
    "\n",
    "Consider only trips that started on the 15th of October.\n",
    "\n",
    "- 108,164\n",
    "- 12,856\n",
    "- 452,470\n",
    "- 62,610\n",
    "\n",
    "> [!IMPORTANT]\n",
    "> Be aware of columns order when defining schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64165b-a47a-46a9-ae98-fb1c0b119ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhv_2019_10 = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(fhv_schema) \\\n",
    "    .parquet(out_fhv_path)\n",
    "\n",
    "# temp table for SQL queries\n",
    "fhv_2019_10.registerTempTable('fhv_2019_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374826c3-f6b5-4d09-89aa-a260cde3be20",
   "metadata": {},
   "source": [
    "# Q3 - Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "761348a5-f2b2-4dfa-91f5-4ff8b4b670a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "| trip_date|trip_total|\n",
      "+----------+----------+\n",
      "|2019-10-15|     62610|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select\n",
    "    '2019-10-15'  as trip_date\n",
    "    ,count(1)     as trip_total\n",
    "  from fhv_2019_10\n",
    " where cast(pickup_datetime as date) = date('2019-10-15')\n",
    ";\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e1b0e-c792-451f-bf7a-a6ac7d3a93b9",
   "metadata": {},
   "source": [
    "#\n",
    "### Question 4: \n",
    "\n",
    "**Longest trip for each day** \n",
    "\n",
    "What is the length of the longest trip in the dataset in hours?\n",
    "\n",
    "- 631,152.50 Hours\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f133d-fa80-4d5f-a821-d31e8bc86563",
   "metadata": {},
   "source": [
    "# Q4 - Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550ea079-339a-426e-b597-c88ce9afdf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|longest_trip_hrs|\n",
      "+----------------+\n",
      "|        631152.5|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "with trip_duration as (\n",
    "select\n",
    "     datepart('day', pickup_datetime) as trip_day\n",
    "    ,max(\n",
    "      round(\n",
    "        timestampdiff(minute,\n",
    "          pickup_datetime,\n",
    "          dropoff_datetime)\n",
    "        / 60, 2))                     as duration_hours\n",
    "  from fhv_2019_10\n",
    " group by trip_day\n",
    ")\n",
    "\n",
    "select max(duration_hours) as longest_trip_hrs\n",
    "  from trip_duration\n",
    ";\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2046f4-c855-4113-8b51-b4e015a695dd",
   "metadata": {},
   "source": [
    "#\n",
    "### Question 5: \n",
    "\n",
    "**User Interface**\n",
    "\n",
    "Spark’s User Interface which shows the application's dashboard runs on which local port?\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- 4040\n",
    "- 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad14669-4294-48f9-ac2d-a2835ea1d160",
   "metadata": {},
   "source": [
    "# Q5 - Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e749f278-d25b-4b95-a36e-800aded754dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://spcr:4040'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.uiWebUrl\n",
    "# port extraction .split(':')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd50137-0b79-4d06-bb30-1119645fbeae",
   "metadata": {},
   "source": [
    "#\n",
    "### Question 6: \n",
    "\n",
    "**Least frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark</br>\n",
    "[Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv)\n",
    "\n",
    "Using the zone lookup data and the FHV October 2019 data, what is the name of the LEAST frequent pickup location Zone?</br>\n",
    "\n",
    "- East Chelsea\n",
    "- Jamaica Bay\n",
    "- Union Sq\n",
    "- Crown Heights North"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffd9c7d0-1b85-41c2-bb34-7af93997b167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-05 17:50:47--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240305T165047Z&X-Amz-Expires=300&X-Amz-Signature=add6a5497cccb8f4552ce6e90b63f740ee18c44b827da3f5c48b1a986afbc98d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-05 17:50:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240305T165047Z&X-Amz-Expires=300&X-Amz-Signature=add6a5497cccb8f4552ce6e90b63f740ee18c44b827da3f5c48b1a986afbc98d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv.3’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12,03K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2024-03-05 17:50:47 (14,5 MB/s) - ‘taxi_zone_lookup.csv.3’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cec42cc0-dd83-4081-98d8-43b316b852e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lkp_zone = pd.read_csv('taxi_zone_lookup.csv', nrows=100)\n",
    "df_lkp_zone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc51d6-7d2f-4917-9c9c-c6de36d77c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema_lkpz = spark.createDataFrame(df_lkp_zone).schema\n",
    "f = open('_lkpz_schema_def_', 'w')\n",
    "f.write(str(schema_lkpz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98947cb-a878-4cbb-a32b-199930e6a9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lkpz_schema = types.StructType([\n",
    "     types.StructField('LocationID', types.IntegerType(), True)\n",
    "    ,types.StructField('Borough', types.StringType(), True)\n",
    "    ,types.StructField('Zone', types.StringType(), True)\n",
    "    ,types.StructField('service_zone', types.StringType(), True)\n",
    "])\n",
    "\n",
    "df_lkpz = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(lkpz_schema) \\\n",
    "    .csv('taxi_zone_lookup.csv')\n",
    "\n",
    "df_lkpz.registerTempTable('df_lkpz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9576d097-0a7e-4fc8-a323-a3b5172e3042",
   "metadata": {},
   "source": [
    "# Q6 - Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1676317-38d5-457f-b143-fcab2a7ca0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|       Zone|PickUp|\n",
      "+-----------+------+\n",
      "|Jamaica Bay|     1|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime as D\n",
    "\n",
    "t2 = D.datetime.now()\n",
    "spark.sql(\"\"\"\n",
    "with pu_total as (\n",
    "select\n",
    "     PULocationID\n",
    "    ,count(*) as pickup_total\n",
    "  from fhv_2019_10 a\n",
    " group by PULocationID\n",
    ")\n",
    "\n",
    "\n",
    "select Zone, min(pickup_total) as PickUp\n",
    "  from pu_total a\n",
    "  left join df_lkpz b\n",
    "    on a.PULocationID = b.LocationID\n",
    " group by Zone\n",
    " order by 2\n",
    " limit 1\n",
    ";\n",
    "\"\"\").show()\n",
    "t2 = D.datetime.now()-t2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
